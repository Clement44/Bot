{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr  8 16:43:03 2020\n",
    "\n",
    "@author: clement\n",
    "\"\"\"\n",
    "\n",
    "# Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, SimpleRNN\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from arch import arch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable definition\n",
    "data_folder = 'Data/' # Folder containing the dataset\n",
    "n_days = 1640\n",
    "look_back = 20\n",
    "# Rolling window forecasting\n",
    "window_length = 300\n",
    "\n",
    "\n",
    "# Preallocate the array\n",
    "dataset = np.empty((n_days, 0))\n",
    "\n",
    "# Create list to save assets names\n",
    "assets = []\n",
    "for f in sorted(os.listdir(data_folder)):\n",
    "\n",
    "    # Save assets names\n",
    "    assets.append(f.replace('.csv', ''))\n",
    "\n",
    "    # Load data\n",
    "    asset = pd.read_csv(data_folder + f, sep=',', usecols=[2, 3], engine='python')\n",
    "    asset = asset.values[:n_days]\n",
    " \n",
    "    # Ensure all data is float\n",
    "    asset = asset.astype('float32')\n",
    "    dataset = np.append(dataset, asset, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = []\n",
    "qlike = []\n",
    "\n",
    "# Visualize returns and volatility of the first asset\n",
    "i = 0\n",
    "plt.plot(dataset[:, 0], label='returns')\n",
    "plt.plot(dataset[:, 1], label='volatility')\n",
    "plt.legend()\n",
    "plt.title(assets[0])\n",
    "plt.xlabel('Time (days)')\n",
    "plt.show()\n",
    "\n",
    "# Normalize data\n",
    "factor = 2\n",
    "\n",
    "# Calculate second raw moment\n",
    "M2 = np.mean(dataset ** 2, axis=0) ** (1/2)\n",
    "\n",
    "# Apply scaling\n",
    "dataset_norm = (1/factor) * (dataset / M2)\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    \"\"\"\n",
    "    Function to convert series from dataset to supervised learning problem\n",
    "    \"\"\"\n",
    "    data_x, data_y = [], []\n",
    "\n",
    "    for i in range(len(dataset) - look_back):\n",
    "\n",
    "        # Create sequence of length equal to look_back\n",
    "        x = dataset[i:(i + look_back), :]\n",
    "        data_x.append(x)\n",
    "\n",
    "        # Take just the volatility for the target\n",
    "        data_y.append(dataset[i + look_back, 1::2])\n",
    "\n",
    "    return np.array(data_x), np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert series to supervised learning problem\n",
    "look_back = 20\n",
    "X, y = create_dataset(dataset_norm, look_back)\n",
    "\n",
    "# Declare variables\n",
    "n_features = dataset.shape[1]\n",
    "n_assets = y.shape[1]\n",
    "\n",
    "# Split dataset\n",
    "training_days = 300\n",
    "X_train, X_test = X[:training_days], X[training_days:]\n",
    "y_train, y_test = y[:training_days], y[training_days:]\n",
    "\n",
    "# Prepare the 3D input vector for the LSTM\n",
    "X_train = np.reshape(X_train, (-1, look_back, n_features))\n",
    "X_test = np.reshape(X_test, (-1, look_back, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(58,\n",
    "               input_shape=(look_back, n_features),\n",
    "               batch_size=batch_size,\n",
    "               stateful=True,\n",
    "               activity_regularizer=regularizers.l1_l2(),\n",
    "               recurrent_regularizer=regularizers.l1_l2()))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_assets, activation='sigmoid'))\n",
    "\n",
    "# Compile the LSTM model\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "\n",
    "## Training and evaluating the model (On-line learning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty arrays\n",
    "y_pred = np.empty((0, n_assets))\n",
    "y_true = np.empty((0, n_assets))\n",
    "\n",
    "for j in range(training_days - look_back + 1, X.shape[0]):\n",
    "\n",
    "    if j == (training_days - look_back + 1):\n",
    "\n",
    "        # First training days for training\n",
    "        X_train = X[:j]\n",
    "        y_train = y[:j]\n",
    "\n",
    "        # Next day for forecasting\n",
    "        X_test = X[j].reshape(1, look_back, n_features)\n",
    "\n",
    "        # Ensure the correct shape for LSTM\n",
    "        X_test = np.tile(X_test, (batch_size, 1, 1))\n",
    "        y_test = np.tile(y[j], (batch_size, 1))\n",
    "\n",
    "        # Training epochs\n",
    "        epochs = 300\n",
    "    \n",
    "    else:\n",
    "\n",
    "        # Available data to refine network state\n",
    "        X_train = X_test\n",
    "        y_train = y_test\n",
    "\n",
    "        # Ensure the correct shape for LSTM\n",
    "        X_test = X[j].reshape(1, look_back, n_features)\n",
    "        X_test = np.tile(X_test, (batch_size, 1, 1))\n",
    "        y_test = np.tile(y[j], (batch_size, 1))\n",
    "\n",
    "        # Epochs for updating\n",
    "        epochs = 20\n",
    "        \n",
    "    # Fit the model\n",
    "    for i in range(epochs):\n",
    "        model.fit(X_train,\n",
    "                  y_train,\n",
    "                  epochs=1,\n",
    "                  batch_size=batch_size,\n",
    "                  verbose=0,\n",
    "                  shuffle=False)\n",
    "        model.reset_states()\n",
    "    \n",
    "    # Evaluate the model\n",
    "    # Make predictions\n",
    "    predicted_output = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    predicted_output = predicted_output[0].reshape(1, n_assets)\n",
    "    true_output = y_test[0].reshape(1, n_assets)\n",
    "\n",
    "    # Save current prediction into an array\n",
    "    y_pred = np.append(y_pred, predicted_output, axis=0)\n",
    "    y_true = np.append(y_true, true_output, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert scaling\n",
    "def invert_standardization(data, M2, factor):\n",
    "  \n",
    "    # Consider just volatility series\n",
    "    M2 = M2[1::2]\n",
    "\n",
    "    data = factor * data * M2\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "# Apply inversion\n",
    "y_pred = invert_standardization(y_pred, M2, factor)\n",
    "y_true = invert_standardization(y_true, M2, factor)\n",
    "\n",
    "def evaluate(y_true, y_pred, folder):\n",
    "    \"\"\"\n",
    "    Function to calculate MSE and QLIKE\n",
    "    \"\"\"\n",
    "\n",
    "    mse = []\n",
    "    qlike = []\n",
    "\n",
    "    for i in range(0, 29):\n",
    "        mse_i = (y_true[:, i] - y_pred[:, i]) ** 2\n",
    "        qlike_i = np.log(y_pred[:, i]) + (y_true[:, i] /  y_pred[:, i])\n",
    "\n",
    "        # save results (point by point)\n",
    "        results = np.array([mse_i, qlike_i]).transpose()\n",
    "        np.savetxt(folder + assets[i] + '.csv', results, delimiter=',', header='MSE, Q-LIKE', fmt='%10.5f', comments='')\n",
    "\n",
    "        mse.append(np.mean(mse_i, axis=0))\n",
    "        qlike.append(np.mean(qlike_i, axis=0))\n",
    "\n",
    "    return mse, qlike\n",
    "\n",
    "# Apply EVALUATE function to predictions\n",
    "mse, qlike = evaluate(y_true, y_pred, '2-OL/')\n",
    "\n",
    "# save results\n",
    "results = np.array([mse, qlike]).transpose()\n",
    "np.savetxt('results/2.csv', results, delimiter=',', header='MSE,Q-LIKE', fmt='%10.5f', comments='')\n",
    "\n",
    "df = pd.DataFrame({'MSE': mse, 'QLIKE': qlike})\n",
    "print(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
